# DSP algorithms behind the Chase Bliss Lossy pedal

**The Chase Bliss Lossy pedal uses spectral (FFT/STFT) processing — not traditional bitcrushing — to emulate lossy audio codec artifacts in real time.** Developed in collaboration with **Goodhertz** (not Cooper FX, who collaborated on the separate *Generation Loss* pedal), the Lossy is a hardware translation of the Goodhertz Lossy plugin, engineered primarily by **Devin Kerr**, Goodhertz co-founder. The pedal decomposes audio into the frequency domain and selectively degrades spectral content, mimicking how perceptual codecs like MP3 discard information. This makes it fundamentally different from bitcrushers or sample rate reducers, which operate in the time domain. The result is the characteristic "underwater," spectrally smeared sound of low-bitrate compressed audio — a sound Kerr describes as having "no equivalent in either plugin or pedal form."

---

## The Lossy pedal's architecture and control mapping

The pedal's signal flow, documented in its official manual, runs: **Input → Loss → Packets → Filter → Verb → Freeze → Gate → Limiter → Output**. This chain maps onto six knobs, three toggle switches, two footswitches, and 16 dip switches, each controlling specific DSP parameters.

The three-way **Mode** toggle selects between three loss algorithms. **Standard** mode emulates lossy data compression artifacts — a darker sound "stuffed full of chiming spectral harmonics," reminiscent of low-bitrate MP3. **Inverse** mode outputs the spectral complement: everything Standard strips away, Inverse retains. **Jitter** mode emulates timing and phase inaccuracies from imperfect digital clocking. These modes strongly suggest an STFT-based architecture where spectral bins are selectively attenuated, zeroed, or phase-perturbed.

The **Speed** knob controls the rate at which the loss algorithm operates — slower speeds produce more spectral smear (consistent with longer FFT windows providing better frequency resolution but worse temporal resolution), while faster speeds sound "more garbled" (shorter windows, more temporal artifacts). The **Loss** knob controls degradation depth — how aggressively spectral content is removed or quantized. The **Global** knob acts as a master intensity control across all processing stages.

The three-way **Packets** toggle adds network-degradation simulation: **Packet Loss** creates gaps and silences mimicking a bad connection, **Packet Repeat** fills those gaps with frozen/repeated audio (glitch-stutter effects), and **Clean** bypasses packet processing entirely. The filter section offers band-pass or band-reject (notch) filtering with three slope options (**6 dB, 24 dB, and 96 dB** per octave, with increasing resonance), controlled by **Filter** (width) and **Freq** (center frequency) knobs. The **Verb** knob blends in a deliberately lo-fi digital reverb described as "fizzling and sputtering," reminiscent of early 1990s electronic music reverbs.

The **Freeze** footswitch engages a spectral freeze — a captured spectral snapshot of the input that can either evolve ("slushy" mode, where the frozen spectrum updates at a rate set by Speed) or remain static ("solid state" mode). The **Slow** dip switch is particularly revealing: it "captures the classic sound of the Lossy plugin — bigger, darker, slower, and with more latency," confirming that the pedal's default mode uses shorter FFT windows optimized for low-latency live performance, while Slow mode uses longer windows matching the plugin's desktop processing.

The hardware draws **~400 mA** at 9V — far more than FV-1-based pedals (~100–150 mA) — indicating a significantly more powerful processor capable of real-time FFT processing. The specific DSP chip has not been publicly disclosed, but Goodhertz described shipping "a desktop-class effect in pedal form," and development was described as "much closer to starting from scratch" than a direct port.

---

## How MP3 compression creates artifacts at the algorithmic level

Understanding what the Lossy emulates requires understanding how perceptual audio codecs generate artifacts. MP3 (MPEG-1 Layer III) processes audio in **frames of 1152 samples** (~26 ms at 44.1 kHz) through a hybrid filterbank: a polyphase quadrature mirror filter splits the signal into **32 equal-width subbands** (~689 Hz each), then each subband undergoes a **Modified Discrete Cosine Transform (MDCT)**, yielding **576 frequency lines** per granule. The MDCT uses either long blocks (36-point, good frequency resolution) or short blocks (12-point, 3 windows, better temporal resolution for transients).

A parallel psychoacoustic model computes masking thresholds using a 1024-point DFT. The model identifies tonal vs. noise-like components using an unpredictability measure, then calculates simultaneous (spectral) masking — where loud components render nearby quiet frequencies inaudible — using a spreading function in the Bark domain. The masking threshold approximation follows:

**SF(Δz) = 15.81 + 7.5(Δz + 0.474) − 17.5√(1 + (Δz + 0.474)²) dB**

The model outputs a signal-to-mask ratio (SMR) for each of ~21 scalefactor bands, which drives the critical quantization stage. MP3 uses a **nonuniform power-law quantizer**: ix[i] = nint(|xr[i]|^0.75 / quantizer_step − 0.0946). A nested two-loop iteration adjusts quantization: the inner loop tunes the global step size until Huffman-coded output fits the bit budget, while the outer loop checks whether quantization noise in each band exceeds the psychoacoustic threshold, increasing per-band scalefactors as needed.

When bitrate is insufficient, specific artifacts emerge. **Pre-echo** occurs when a transient encoded with a long MDCT window spreads quantization noise across the entire ~26 ms window, making noise audible before the attack. **Spectral holes** appear when the encoder "runs out of bits" and quantizes entire scalefactor bands to zero — creating unnatural silent frequency regions. The hallmark **"underwater" or "swimming" sound** arises not from removing partials per se, but from **removing different partials in different frames**. As one KVR Audio analysis explains: "rapidly-fluctuating gains at different frequencies because things are either flipping above/below the noise floor or because their levels are being quantised." This random frame-to-frame amplitude modulation across the spectrum produces the characteristic bubbling/warbling quality. **Birdie artifacts** (brief chirp-like tones) occur when isolated spectral components survive quantization in one frame but vanish in adjacent frames. **Temporal smearing** spreads sharp transients across the window length — at low bitrates, a sub-2 ms event can smear over 35–130 ms.

---

## Real-time approaches to emulating lossy codec artifacts

Three distinct strategies exist for real-time lossy emulation, ranging from literal to approximate.

**The literal approach embeds actual codec encoders.** The open-source **MAIM** plugin (by Arden Butterfield, GPL-licensed) runs two actual MP3 encoders — LAME and BladeEnc — in real time. Audio feeds into the encoder, gets compressed to an MP3 bitstream, then immediately decodes back to PCM. Butterfield "circuit-bent" the encoder internals: flipping signs, misaligning data, sending values down wrong code paths to expose and exaggerate artifact characteristics. Latency is inherent (~26 ms per MP3 frame), and computational cost is moderate but manageable. This produces the most authentic artifacts but offers limited real-time parameter control over artifact character.

**The spectral quantization approach — likely closest to what Goodhertz Lossy uses — operates in the frequency domain without a full codec.** Tim O'Brien's Stanford CCRMA paper "Implementations of Uniform Frequency-Domain Quantization as Audio Effect" (2013) describes the core algorithm: (1) window the input with a Hann window in an overlap-add STFT framework, (2) compute the FFT, (3) apply uniform mid-tread quantization to FFT magnitudes at R bits: Q(X[k]) = Δ · round(X[k]/Δ), where Δ = 2·max(|X|)/2^R, (4) IFFT and overlap-add. O'Brien found that frequency-domain quantization produces "more varied and desirable distortion" than time-domain bitcrushing, creating both spectral and temporal distortion: transients smear over the transform block, chirp signals exhibit reverb-like smearing and pre-echo, and white noise undergoes significant spectral reshaping. FFT size of **1024–2048** (corresponding to MP3's ~26 ms frame) with magnitude quantization to **4–8 bits** produces heavy effects; 12–16 bits yields subtle degradation. Phase can be left intact (more natural) or also quantized (more destructive).

**The spectral gating/thinning approach** provides perhaps the most controllable emulation. The algorithm zeroes out spectral bins below a threshold that varies frame-to-frame, mimicking how perceptual codecs discard sub-threshold components. A frequency-dependent threshold based on the absolute threshold of hearing curve (ATH) can be applied. Crucially, **randomly varying which bins get zeroed between frames** reproduces the "underwater" warbling — the signature sound of aggressive codec compression. One KVR forum contributor noted that "35 notch EQs at different frequencies with randomly modulated wet/dry mix" approximates the same effect, confirming that the core mechanism is frame-varying spectral amplitude modulation. Additional techniques include hard low-pass filtering at 11–16 kHz (mimicking MP3 bandwidth limiting at low bitrates), MDCT-domain quantization with time-domain aliasing (more faithful to actual codec architecture), and noise shaping that follows the spectral envelope of the signal.

Based on developer commentary and observed behavior, the Goodhertz Lossy likely combines spectral quantization and gating in an STFT framework, with the **Speed** knob mapping to FFT hop size or window length, the **Loss** knob mapping to quantization depth or spectral gate threshold, and the **Mode** switch selecting different spectral manipulation strategies (Standard keeps the "codec-processed" result, Inverse keeps the residual, Jitter perturbs phase relationships).

---

## Bit-crushing and sample rate reduction as complementary techniques

While the Lossy pedal operates spectrally, traditional time-domain degradation effects provide important context for lo-fi DSP.

**Bit-crushing** reduces quantization levels through a straightforward formula: output = floor(input × quant) / quant, where quant = 2^(bits−1). Each bit provides approximately **6.02 dB** of dynamic range (SQNR ≈ 6.02N + 1.76 dB for a full-scale sine). At **12 bits** (Akai S900, SP-1200, Fairlight CMI), the sound acquires subtle warmth and a "fuzzy" edge — the golden zone of lo-fi. At **8 bits** (NES, Commodore 64), stepped distortion becomes clearly audible. At **4 bits**, only 16 amplitude levels remain, producing aggressive staircase distortion. Fractional bit-crushing uses `powf(2.0, bits_fractional)` where bits can be any float value, enabling smooth knob sweeps between integer depths. For lo-fi effects, dithering is deliberately omitted because the correlated quantization distortion *is* the desired effect.

**Sample rate reduction** uses a zero-order hold (ZOH): hold each sample value for N input samples before updating. The ZOH has a frequency response of sinc(f/fs_new), introducing characteristic roll-off and creating aliasing when frequencies above the reduced Nyquist fold back as inharmonic content. "Dirty" downsampling (without anti-aliasing filter) is preferred for lo-fi effects precisely because the aliasing produces metallic, inharmonic overtones reminiscent of early digital hardware. Variable rate reduction uses a floating-point phase accumulator: increment a phase counter by 1.0 each sample, update the held value when phase exceeds the rate factor, then subtract the rate factor (preserving the fractional part for accurate timing).

These techniques sound fundamentally different from codec emulation. As Devin Kerr noted: "Bit crushers & sample rate reducers are incredibly common...But in daily life it's much more common to hear lossy compression: spectral artifacts, data compression, transient smearing, which sounds nothing like a bit crusher." The distinction is critical — bitcrushing creates *amplitude* distortion (staircase waveforms), while codec emulation creates *spectral* distortion (frequency-domain artifacts that vary over time).

---

## Buffer degradation, packet loss, and glitch algorithms

The Lossy's Packet Loss and Packet Repeat modes simulate network audio degradation using buffer manipulation techniques.

**Packet loss simulation** models bursty network dropout using a **Gilbert-Elliott Markov model**, where the probability of losing the current packet depends on whether the previous packet was lost. This creates realistic burst patterns rather than uniform random drops. Real network audio operates in frames (typically 10–60 ms), so loss occurs at packet granularity. During a dropout, the algorithm can output silence (complete loss), repeat the last good packet (buffer freeze — this is what Packet Repeat mode does), or interpolate. The characteristic sound of streaming audio degradation combines these dropouts with the codec artifacts from the Loss section.

**Stutter/repeat effects** capture small segments into a buffer and loop them. The repeated segment's length determines character: quarter-note repeats create rhythmic loops, sixteenth-note repeats create machine-gun stutter, and very short segments (sub-10 ms) transition from rhythmic to tonal — the repeated segment becomes a pitched buzz. This connects to **granular synthesis**, the formal framework behind glitch effects: small grains (1–500 ms) are captured, windowed (Hann or triangle envelope to prevent clicks), potentially pitch-shifted or reordered, then overlap-added for reconstruction.

**Spectral freeze** — the Lossy's distinctive feature — captures an FFT snapshot and continuously resynthesizes it. In "slushy" mode, the frozen spectrum updates at a rate controlled by Speed, creating an evolving spectral pad that tracks the input. In "solid" mode, the spectrum is truly frozen. The Freezer hidden parameter controls the balance between live input and frozen signal, while the Gate function applies a noise gate to clean up residual artifacts.

---

## Open-source implementations and research references

Several open-source projects implement these techniques with full source code available.

**MAIM** (github.com/ArdenButterfield/Maim, GPL) is the most authentic MP3 artifact emulator, embedding actual LAME and BladeEnc encoders with exposed "circuit-bent" internals. **The Stanford CCRMA Frequantizer** (github.com/tsob/frequantizer) implements O'Brien's frequency-domain quantization in SuperCollider and C++/Faust — the most directly relevant reference for understanding Lossy-style spectral degradation. **CHOW Tape Model** (github.com/jatinchowdhury18/AnalogTapeModel, GPL) is the definitive open-source tape emulation, implementing a Jiles-Atherton hysteresis model solved via RK4, Newton-Raphson, or neural network, with full documentation in Chowdhury's DAFx-2019 paper. **C1Bitcrusher** (github.com/datajake1999/C1Bitcrusher, LGPL) provides a bit-exact bitcrusher implementation with dithering options. The **Effetune** project (github.com/Frieve-A/effetune) includes a Digital Error Emulator that simulates transmission errors alongside standard lo-fi effects.

Among commercial plugins with published technical insights, **D16 Decimort 2** models the full ADC/DAC signal path of classic samplers (SP-1200, MPC60) rather than simple bitcrushing. **Unfiltered Audio LO-FI-AF** includes a "Spectral" module explicitly implementing FFT-based MP3 artifact effects through spectral gating. **Sonnox Oxford Pro-Codec** (developed with Fraunhofer IIS, the creators of MP3) provides real-time codec auditioning with artifact metering. The **Zynaptiq UNCHIRP** plugin approaches the problem in reverse — removing codec artifacts — and its documentation provides insight into what those artifacts look like algorithmically.

Key academic references include O'Brien's "Implementations of Uniform Frequency-Domain Quantization as Audio Effect" (Stanford CCRMA, 2013), Chowdhury's "Real-Time Physical Modelling for Analog Tape Machines" (DAFx-2019), Jürgen Herre's tutorial on temporal noise shaping and quantization in perceptual audio coding (mp3-tech.org), and the comprehensive "Psychoacoustic Models for Perceptual Audio Coding — A Tutorial Review" (MDPI Applied Sciences, 2019). The musicdsp.org archive contains practical implementations of bitcrushers and decimators, while KVR Audio's forum threads on "underwater" FFT sounds and real-time MP3 emulation contain expert analysis of spectral artifact mechanisms.

---

## Conclusion

Recreating Lossy-style effects in software requires a fundamentally different approach from traditional lo-fi processing. The core algorithm is **STFT-based spectral manipulation**: transform audio to the frequency domain using overlapping windowed FFTs, then degrade spectral content through quantization, gating, or zeroing of bins — with the critical detail that **degradation must vary between frames** to produce the signature "underwater" codec sound. The FFT window size controls the frequency/temporal resolution tradeoff (and thus the Speed parameter's behavior), while the quantization depth or gate threshold controls Loss intensity. Inverse mode simply outputs the spectral residual (original minus processed). Packet effects layer buffer-manipulation techniques (silence insertion, segment repetition) on top of the spectral processing. The spectral freeze captures and resynthesizes an FFT magnitude snapshot.

The most productive starting point for implementation would be the Stanford CCRMA Frequantizer code for the spectral quantization core, MAIM's source for reference on authentic codec behavior, and a Gilbert-Elliott packet loss model for the buffer degradation layer. The key insight that separates good lossy emulation from naive approaches is that **codec artifacts are spectral phenomena that vary over time** — it is the inconsistency between adjacent analysis frames, not static spectral filtering, that creates the characteristic sound.